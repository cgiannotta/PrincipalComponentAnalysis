{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Explain\n",
    "\n",
    "### Decision Tree\n",
    "* purity/impurity\n",
    "* entropy vs. Gini index\n",
    "* using decision tree for prediction\n",
    "\n",
    "### Random Forest\n",
    "* bootstrap aggregating\n",
    "* OOB error estimating\n",
    "* pros and cons of random forest\n",
    "\n",
    "### Extra\n",
    "* compare classification with sci-kit learn functions vs. random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619, 0], [502, 0], [645, 1], [822, 1], [376, 0], [501, 1], [684, 1], [528, 1], [616, 1], [653, 1]]\n",
      "[1, 1, 1, 0, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "with open(\"ChurnTest.csv\", newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        X.append([int(num) for num in line[0:-1]]) # save features to X list\n",
    "        y.append(int(line[-1])) # save class to y list\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"ChurnTest.csv\").to_numpy()\n",
    "#data.head()\n",
    "#data[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(data[:,0:-1], axis=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"Churn.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"Churn.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.FacetGrid(data, hue=\"Y\", height=4).map(plt.scatter, \"X1\", \"X2\").add_legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate metric for split (entropy)\n",
    "#def calc_entropy(obs_list):\n",
    "#    ent = 0\n",
    " #   for unique_class in set(obs_list.iloc[:,-1]):\n",
    "  #      prop = len(obs_list[obs_list.iloc[:,-1]==unique_class]) / len(obs_list)\n",
    "   #     ent += (-1 * prop) * np.log2(prop)\n",
    "    #return ent\n",
    "\n",
    "#calc_entropy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to calculate cost function for split (entropy)\n",
    "def calc_entropy(y_vals):\n",
    "    ent = 0\n",
    "    for y_val in set(y_vals):\n",
    "        prop = len([val for val in y_vals if val==y_val]) / len(y_vals)\n",
    "        ent += (-1 * prop) * np.log2(prop) # update entropy using formula\n",
    "    return ent\n",
    "\n",
    "calc_entropy(y)\n",
    "#calc_entropy(data[:,-1])\n",
    "#test_list = [1, 0, 1, 1, 1]\n",
    "#calc_entropy(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left:  [[502, 0], [376, 0], [501, 1]] [1, 1, 0]\n",
      "right:  [[619, 0], [645, 1], [822, 1], [684, 1], [528, 1], [616, 1], [653, 1]] [1, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# new function to split data\n",
    "def split_data(pred_idx, pred_val, X_vals, y_vals):\n",
    "    X_left, X_right, y_left, y_right = [], [], [], []\n",
    "    for i in range(len(X_vals)):\n",
    "        if X_vals[i][pred_idx] < pred_val:\n",
    "            X_left.append(X_vals[i])\n",
    "            y_left.append(y_vals[i])\n",
    "        else:\n",
    "            X_right.append(X_vals[i])\n",
    "            y_right.append(y_vals[i])\n",
    "    return X_left, X_right, y_left, y_right\n",
    "\n",
    "X_left, X_right, y_left, y_right = split_data(0, 510, X, y)\n",
    "print(\"left: \", X_left, y_left)\n",
    "print(\"right: \", X_right, y_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data\n",
    "#def split_data(pred_idx, pred_val, data):\n",
    " #   left_node = data[data[:,pred_idx] < pred_val] # left holds obs with vals less than pred_val\n",
    "  #  right_node = data[data[:,pred_idx] >= pred_val] # right holds obs with vals greater than or equal to pred_val\n",
    "   # return left_node, right_node\n",
    "\n",
    "#left, right = split_data(0, 600, data)\n",
    "#print(\"left: \", left)\n",
    "#print(\"right: \", right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034851554559677034"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to calculate information gain\n",
    "def calc_infogain(parent_yvals, left_yvals, right_yvals):\n",
    "    H = calc_entropy(parent_yvals) # entropy of parent node\n",
    "    #print(\"H: \", H)\n",
    "    H_left = calc_entropy(left_yvals) # entropy of left child node\n",
    "    #print(\"H_left: \", H_left)\n",
    "    H_right = calc_entropy(right_yvals) # entropy of right child node\n",
    "    #print(\"H_right: \", H_right)\n",
    "    P_left = len(left_yvals) / len(parent_yvals)\n",
    "    P_right = len(right_yvals) / len(parent_yvals)\n",
    "    cond_entropy = (H_left * P_left) + (H_right * P_right) # conditional entropy to compare to parent node\n",
    "    #print(\"cond_entropy: \", cond_entropy)\n",
    "    return H - cond_entropy # difference between parent node and child node entropy\n",
    "\n",
    "#parent_y = data[:,-1]\n",
    "#left_node, right_node = split_data(0, 600, data)\n",
    "#print(left_node)\n",
    "#print(right_node)\n",
    "#calc_infogain(parent_y, [obs[-1] for obs in left_node], [obs[-1] for obs in right_node])\n",
    "calc_infogain(y, y_left, y_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_infogain 0.10371609984200658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred_idx': 2,\n",
       " 'pred_val': 40.3972,\n",
       " 'left': array([[3.7600000e+02, 0.0000000e+00, 2.9000000e+01, ..., 0.0000000e+00,\n",
       "         1.1934688e+05, 1.0000000e+00],\n",
       "        [6.8400000e+02, 1.0000000e+00, 2.7000000e+01, ..., 1.0000000e+00,\n",
       "         7.1725730e+04, 0.0000000e+00],\n",
       "        [5.2800000e+02, 1.0000000e+00, 3.1000000e+01, ..., 0.0000000e+00,\n",
       "         8.0181120e+04, 0.0000000e+00],\n",
       "        ...,\n",
       "        [5.1600000e+02, 1.0000000e+00, 3.5000000e+01, ..., 1.0000000e+00,\n",
       "         1.0169977e+05, 0.0000000e+00],\n",
       "        [7.0900000e+02, 0.0000000e+00, 3.6000000e+01, ..., 1.0000000e+00,\n",
       "         4.2085580e+04, 1.0000000e+00],\n",
       "        [7.9200000e+02, 0.0000000e+00, 2.8000000e+01, ..., 0.0000000e+00,\n",
       "         3.8190780e+04, 0.0000000e+00]]),\n",
       " 'right': array([[6.1900000e+02, 0.0000000e+00, 4.2000000e+01, ..., 1.0000000e+00,\n",
       "         1.0134888e+05, 1.0000000e+00],\n",
       "        [5.0200000e+02, 0.0000000e+00, 4.2000000e+01, ..., 0.0000000e+00,\n",
       "         1.1393157e+05, 1.0000000e+00],\n",
       "        [6.4500000e+02, 1.0000000e+00, 4.4000000e+01, ..., 0.0000000e+00,\n",
       "         1.4975671e+05, 1.0000000e+00],\n",
       "        ...,\n",
       "        [6.5500000e+02, 0.0000000e+00, 4.6000000e+01, ..., 0.0000000e+00,\n",
       "         1.1514640e+05, 1.0000000e+00],\n",
       "        [5.9700000e+02, 0.0000000e+00, 5.3000000e+01, ..., 0.0000000e+00,\n",
       "         6.9384710e+04, 1.0000000e+00],\n",
       "        [7.7200000e+02, 1.0000000e+00, 4.2000000e+01, ..., 0.0000000e+00,\n",
       "         9.2888520e+04, 1.0000000e+00]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to determine best split (or no split)\n",
    "def best_split(data):\n",
    "    y_vals = data[:,-1] # extract response values from data\n",
    "    #max_infogain = 0\n",
    "    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total # predictors\n",
    "    pred_idxs_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\n",
    "    pred_vals_to_test = np.mean(data[:,0:-1], axis=0)[pred_idxs_to_test] # use mean value for each predictor as split value\n",
    "    #print(pred_idxs_to_test)\n",
    "    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\n",
    "    max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, None, None\n",
    "    for i in range(len(pred_idxs_to_test)): # for each predictor in random subset\n",
    "        left, right = split_data(pred_idxs_to_test[i], pred_vals_to_test[i], data) # split data on mean value for each predictor\n",
    "        #infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\n",
    "        infogain = calc_infogain(y_vals, left[:,-1], right[:,-1])\n",
    "        if infogain > max_infogain: # determine if split increases information gain / reduces entropy\n",
    "            max_infogain = infogain\n",
    "            best_idx = pred_idxs_to_test[i]\n",
    "            best_val = pred_vals_to_test[i]\n",
    "            best_left, best_right = left, right\n",
    "    print(\"max_infogain\", max_infogain)\n",
    "    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\n",
    "\n",
    "best_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def best_split(data):\\n    y_vals = data[:,-1] # extract response values from data\\n    max_infogain = 0\\n    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total predictors\\n    pred_vals_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\\n    print(pred_vals_to_test)\\n    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\\n    for idx in pred_vals_to_test:\\n        for row in data:\\n            left, right = split_data(idx, row[idx], data)\\n            infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\\n            #print(\"infogain: \", infogain)\\n            if infogain > max_infogain:\\n                max_infogain = infogain\\n                best_idx = idx\\n                best_val = row[idx]\\n                best_left, best_right = left, right\\n    print(\"max_infogain\", max_infogain)\\n    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\\n\\nbest_split(data)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old\n",
    "# function to determine best split (or no split)\n",
    "'''def best_split(data):\n",
    "    y_vals = data[:,-1] # extract response values from data\n",
    "    max_infogain = 0\n",
    "    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total predictors\n",
    "    pred_vals_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\n",
    "    print(pred_vals_to_test)\n",
    "    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\n",
    "    for idx in pred_vals_to_test:\n",
    "        for row in data:\n",
    "            left, right = split_data(idx, row[idx], data)\n",
    "            infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\n",
    "            #print(\"infogain: \", infogain)\n",
    "            if infogain > max_infogain:\n",
    "                max_infogain = infogain\n",
    "                best_idx = idx\n",
    "                best_val = row[idx]\n",
    "                best_left, best_right = left, right\n",
    "    print(\"max_infogain\", max_infogain)\n",
    "    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\n",
    "\n",
    "best_split(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build decision tree\n",
    "def build_tree(params):\n",
    "    return \"tree has been built!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "http://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15381-s06/www/DTs.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
