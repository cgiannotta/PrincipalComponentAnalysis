{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Explain\n",
    "\n",
    "### Decision Tree\n",
    "* purity/impurity\n",
    "* entropy vs. Gini index\n",
    "* using decision tree for prediction\n",
    "\n",
    "### Random Forest\n",
    "* bootstrap aggregating\n",
    "* OOB error estimating\n",
    "* pros and cons of random forest\n",
    "\n",
    "### Extra\n",
    "* compare classification with sci-kit learn functions vs. random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "#with open(\"Churn.csv\", newline=\"\") as f:\n",
    "with open(\"ChurnTestMedium.csv\", newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        X.append([float(num) for num in line[0:-1]]) # save features to X list\n",
    "        y.append(int(line[-1])) # save class to y list\n",
    "\n",
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(self, depth=0):\n",
    "    def init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"ChurnTest.csv\").to_numpy()\n",
    "#data.head()\n",
    "#data[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(data[:,0:-1], axis=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"Churn.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"Churn.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.FacetGrid(data, hue=\"Y\", height=4).map(plt.scatter, \"X1\", \"X2\").add_legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate metric for split (entropy)\n",
    "#def calc_entropy(obs_list):\n",
    "#    ent = 0\n",
    " #   for unique_class in set(obs_list.iloc[:,-1]):\n",
    "  #      prop = len(obs_list[obs_list.iloc[:,-1]==unique_class]) / len(obs_list)\n",
    "   #     ent += (-1 * prop) * np.log2(prop)\n",
    "    #return ent\n",
    "\n",
    "#calc_entropy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927744539878083"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to calculate cost function for split (entropy)\n",
    "def calc_entropy(y_vals):\n",
    "    ent = 0\n",
    "    for y_val in set(y_vals):\n",
    "        prop = len([val for val in y_vals if val==y_val]) / len(y_vals)\n",
    "        ent += (-1 * prop) * np.log2(prop) # update entropy using formula\n",
    "    return ent\n",
    "\n",
    "calc_entropy(y)\n",
    "#calc_entropy(data[:,-1])\n",
    "#test_list = [1, 0, 1, 1, 1]\n",
    "#calc_entropy(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new function to split data\n",
    "def split_data(pred_idx, pred_val, X_vals, y_vals):\n",
    "    X_left, X_right, y_left, y_right = [], [], [], []\n",
    "    for i in range(len(X_vals)):\n",
    "        if X_vals[i][pred_idx] < pred_val:\n",
    "            X_left.append(X_vals[i])\n",
    "            y_left.append(y_vals[i])\n",
    "        else:\n",
    "            X_right.append(X_vals[i])\n",
    "            y_right.append(y_vals[i])\n",
    "    return X_left, X_right, y_left, y_right\n",
    "\n",
    "#X_left, X_right, y_left, y_right = split_data(0, 510, X, y)\n",
    "#print(\"left: \", X_left, y_left)\n",
    "#print(\"right: \", X_right, y_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01100085281782226"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to calculate information gain\n",
    "def calc_infogain(parent_yvals, left_yvals, right_yvals):\n",
    "    H = calc_entropy(parent_yvals) # entropy of parent node\n",
    "    #print(\"H: \", H)\n",
    "    H_left = calc_entropy(left_yvals) # entropy of left child node\n",
    "    #print(\"H_left: \", H_left)\n",
    "    H_right = calc_entropy(right_yvals) # entropy of right child node\n",
    "    #print(\"H_right: \", H_right)\n",
    "    P_left = len(left_yvals) / len(parent_yvals)\n",
    "    P_right = len(right_yvals) / len(parent_yvals)\n",
    "    cond_entropy = (H_left * P_left) + (H_right * P_right) # conditional entropy to compare to parent node\n",
    "    #print(\"cond_entropy: \", cond_entropy)\n",
    "    return H - cond_entropy # difference between parent node and child node entropy\n",
    "\n",
    "#parent_y = data[:,-1]\n",
    "#left_node, right_node = split_data(0, 600, data)\n",
    "#print(left_node)\n",
    "#print(right_node)\n",
    "#calc_infogain(parent_y, [obs[-1] for obs in left_node], [obs[-1] for obs in right_node])\n",
    "X_left, X_right, y_left, y_right = split_data(0, 600, X, y)\n",
    "calc_infogain(y, y_left, y_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.96429275e+04 9.29105800e+04 1.75000000e+00]\n"
     ]
    }
   ],
   "source": [
    "m = int(np.round(np.sqrt(len(X[1])),2)) # set number of predectors to test = sqrt total # predictors\n",
    "pred_idxs_to_test = np.random.choice(range(0,len(X[1])),m, replace=False) # select random subset of predictors to test\n",
    "pred_vals_to_test = np.mean(X, axis=0)[pred_idxs_to_test] # use mean value for each predictor as split value\n",
    "print(pred_vals_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new function to determine best split (or no split)\n",
    "def best_split(X, y):\n",
    "    m = int(np.round(np.sqrt(len(X[1])),2)) # set number of predectors to test = sqrt total # predictors\n",
    "    pred_idxs_to_test = np.random.choice(range(0,len(X[1])),m, replace=False) # select random subset of predictors to test\n",
    "    pred_vals_to_test = np.mean(X, axis=0)[pred_idxs_to_test] # use mean value for each predictor as split value\n",
    "    max_infogain, best_idx, best_val, best_left, best_right = 0, 9999999, 9999999, {}, {}\n",
    "    for i in range(len(pred_idxs_to_test)): # for each predictor in random subset\n",
    "        X_left, X_right, y_left, y_right = split_data(pred_idxs_to_test[i], pred_vals_to_test[i], X, y) # split data on mean value for each predictor\n",
    "        infogain = calc_infogain(y, y_left, y_right)\n",
    "        if infogain > max_infogain: # determine if split increases information gain / reduces entropy\n",
    "            max_infogain = infogain\n",
    "            best_idx = pred_idxs_to_test[i]\n",
    "            best_val = pred_vals_to_test[i]\n",
    "            best_left = {\"X_left\": X_left, \"y_left\": y_left}\n",
    "            best_right = {\"X_right\": X_right, \"y_right\": y_right}\n",
    "    #print(\"max_infogain\", max_infogain)\n",
    "    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\n",
    "\n",
    "#best_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def best_split(data):\\n    y_vals = data[:,-1] # extract response values from data\\n    #max_infogain = 0\\n    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total # predictors\\n    pred_idxs_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\\n    pred_vals_to_test = np.mean(data[:,0:-1], axis=0)[pred_idxs_to_test] # use mean value for each predictor as split value\\n    #print(pred_idxs_to_test)\\n    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\\n    max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, None, None\\n    for i in range(len(pred_idxs_to_test)): # for each predictor in random subset\\n        left, right = split_data(pred_idxs_to_test[i], pred_vals_to_test[i], data) # split data on mean value for each predictor\\n        #infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\\n        infogain = calc_infogain(y_vals, left[:,-1], right[:,-1])\\n        if infogain > max_infogain: # determine if split increases information gain / reduces entropy\\n            max_infogain = infogain\\n            best_idx = pred_idxs_to_test[i]\\n            best_val = pred_vals_to_test[i]\\n            best_left, best_right = left, right\\n    print(\"max_infogain\", max_infogain)\\n    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\\n\\nbest_split(data)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to determine best split (or no split)\n",
    "'''def best_split(data):\n",
    "    y_vals = data[:,-1] # extract response values from data\n",
    "    #max_infogain = 0\n",
    "    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total # predictors\n",
    "    pred_idxs_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\n",
    "    pred_vals_to_test = np.mean(data[:,0:-1], axis=0)[pred_idxs_to_test] # use mean value for each predictor as split value\n",
    "    #print(pred_idxs_to_test)\n",
    "    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\n",
    "    max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, None, None\n",
    "    for i in range(len(pred_idxs_to_test)): # for each predictor in random subset\n",
    "        left, right = split_data(pred_idxs_to_test[i], pred_vals_to_test[i], data) # split data on mean value for each predictor\n",
    "        #infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\n",
    "        infogain = calc_infogain(y_vals, left[:,-1], right[:,-1])\n",
    "        if infogain > max_infogain: # determine if split increases information gain / reduces entropy\n",
    "            max_infogain = infogain\n",
    "            best_idx = pred_idxs_to_test[i]\n",
    "            best_val = pred_vals_to_test[i]\n",
    "            best_left, best_right = left, right\n",
    "    print(\"max_infogain\", max_infogain)\n",
    "    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\n",
    "\n",
    "best_split(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def best_split(data):\\n    y_vals = data[:,-1] # extract response values from data\\n    max_infogain = 0\\n    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total predictors\\n    pred_vals_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\\n    print(pred_vals_to_test)\\n    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\\n    for idx in pred_vals_to_test:\\n        for row in data:\\n            left, right = split_data(idx, row[idx], data)\\n            infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\\n            #print(\"infogain: \", infogain)\\n            if infogain > max_infogain:\\n                max_infogain = infogain\\n                best_idx = idx\\n                best_val = row[idx]\\n                best_left, best_right = left, right\\n    print(\"max_infogain\", max_infogain)\\n    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\\n\\nbest_split(data)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old\n",
    "# function to determine best split (or no split)\n",
    "'''def best_split(data):\n",
    "    y_vals = data[:,-1] # extract response values from data\n",
    "    max_infogain = 0\n",
    "    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total predictors\n",
    "    pred_vals_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\n",
    "    print(pred_vals_to_test)\n",
    "    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\n",
    "    for idx in pred_vals_to_test:\n",
    "        for row in data:\n",
    "            left, right = split_data(idx, row[idx], data)\n",
    "            infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\n",
    "            #print(\"infogain: \", infogain)\n",
    "            if infogain > max_infogain:\n",
    "                max_infogain = infogain\n",
    "                best_idx = idx\n",
    "                best_val = row[idx]\n",
    "                best_left, best_right = left, right\n",
    "    print(\"max_infogain\", max_infogain)\n",
    "    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\n",
    "\n",
    "best_split(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build decision tree\n",
    "def build_tree(X, y):\n",
    "    #tree = best_split(X, y) # get root node with best split for full data\n",
    "    depth = 0 # set initial depth to 0\n",
    "    parent = {} # begin with empty parent node\n",
    "    split_tree(tree, parent, depth) # call recursive function to build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split tree, called recursively\n",
    "def split_tree(node, parent_node, d):\n",
    "    \n",
    "    # save data from node to be used in split if needed\n",
    "    left, right = node[\"left\"], node[\"right\"]\n",
    "    \n",
    "    # delete data from node so can reassign best classification\n",
    "    del(node[\"left\"], node[\"right\"])\n",
    "    \n",
    "    # check if node contains empty dataset\n",
    "    if len(left[\"X_left\"])==0 or len(right[\"X_right\"])==0:\n",
    "        # assign each branch of the node to the most common class from the parent node\n",
    "        node[\"left\"] = max(set(parent_node[\"left\"][\"y_left\"]), key=parent_node[\"left\"][\"y_left\"].count)\n",
    "        node[\"right\"] = max(set(parent_node[\"right\"][\"y_right\"]), key=parent_node[\"right\"][\"y_right\"].count)\n",
    "        return\n",
    "    \n",
    "    # check if tree has been split maximum number of times\n",
    "    elif d >= max_depth:\n",
    "        # assign each branch of the node to the most common class from the parent node\n",
    "        node[\"left\"] = max(set(parent_node[\"left\"][\"y_left\"]), key=parent_node[\"left\"][\"y_left\"].count)\n",
    "        node[\"right\"] = max(set(parent_node[\"right\"][\"y_right\"]), key=parent_node[\"right\"][\"y_right\"].count)\n",
    "        return\n",
    "    else:\n",
    "        # check left and right datasets to see if need to split more or make terminal node\n",
    "        # assess left node\n",
    "        if len(set(left[\"y_left\"]))==1:\n",
    "            # assign left branch of the node to the most common class from the parent node\n",
    "            node[\"left\"] = max(set(parent_node[\"left\"][\"y_left\"]), key=parent_node[\"left\"][\"y_left\"].count)\n",
    "        else:\n",
    "            # split this branch by calling split_tree function\n",
    "            node[\"left\"] = best_split(left[\"X_left\"], left[\"y_left\"])\n",
    "            parent = {\"left\": left, \"right\": right}\n",
    "            split_tree(node[\"left\"], parent, d+1)\n",
    "        # assess right node\n",
    "        if len(set(right[\"y_right\"]))==1:\n",
    "            # assign right branch of the node to the most common class from the parent node\n",
    "            node[\"right\"] = max(set(parent_node[\"right\"][\"y_right\"]), key=parent_node[\"right\"][\"y_right\"].count)\n",
    "            return\n",
    "        else:\n",
    "            # split this branch by calling split_tree function\n",
    "            node[\"right\"] = best_split(right[\"X_right\"], right[\"y_right\"])\n",
    "            parent = {\"left\": left, \"right\": right}\n",
    "            split_tree(node[\"right\"], parent, d+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of trees\n",
    "num_trees = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree:  {'pred_idx': 7, 'pred_val': 0.55, 'left': {'pred_idx': 8, 'pred_val': 104090.83333333333, 'left': {'pred_idx': 8, 'pred_val': 37700.59333333333, 'left': 1, 'right': 1}, 'right': 0}, 'right': {'pred_idx': 8, 'pred_val': 83763.09999999999, 'left': 1, 'right': {'pred_idx': 0, 'pred_val': 613.8, 'left': 0, 'right': {'pred_idx': 2, 'pred_val': 37.5, 'left': 0, 'right': 0}}}}\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "# set maximum depth for tree\n",
    "max_depth = 5\n",
    "# get root node for tree\n",
    "tree = best_split(X, y)\n",
    "# split root node recursively\n",
    "build_tree(X, y)\n",
    "print(\"tree: \", tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "actual vals:  [1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# function to predict classification for new datapoint\n",
    "def predict(x):\n",
    "    curr_node = tree\n",
    "    while True:\n",
    "        if x[curr_node['pred_idx']] < curr_node['pred_val']:\n",
    "            if type(curr_node['left'])==int:\n",
    "                return curr_node['left']\n",
    "            else:\n",
    "                curr_node = curr_node['left']\n",
    "                continue\n",
    "        else:\n",
    "            if type(curr_node['right'])==int:\n",
    "                return curr_node['right']\n",
    "            else:\n",
    "                curr_node = curr_node['right']\n",
    "                continue\n",
    "\n",
    "preds = []\n",
    "for i in range(len(X)):\n",
    "    preds.append(predict(X[i]))\n",
    "print(\"predictions: \", preds)\n",
    "print(\"actual vals: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3\n"
     ]
    }
   ],
   "source": [
    "# function to calculate accuracy\n",
    "def calc_accuracy(y_hat, y):\n",
    "    correct = []\n",
    "    for i in range(len(y_hat)):\n",
    "        correct.append(y_hat[i]==y[i])\n",
    "    return sum(correct) / len(y_hat)\n",
    "    \n",
    "print(\"accuracy: \", calc_accuracy(preds, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "http://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15381-s06/www/DTs.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
