{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Explain\n",
    "\n",
    "### Decision Tree\n",
    "* purity/impurity\n",
    "* entropy vs. Gini index\n",
    "* using decision tree for prediction\n",
    "\n",
    "### Random Forest\n",
    "* bootstrap aggregating\n",
    "* OOB error estimating\n",
    "* pros and cons of random forest\n",
    "\n",
    "### Extra\n",
    "* compare classification with sci-kit learn functions vs. random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619,   0,   1],\n",
       "       [502,   0,   1],\n",
       "       [645,   1,   1],\n",
       "       [822,   1,   0],\n",
       "       [376,   0,   1],\n",
       "       [501,   1,   0],\n",
       "       [684,   1,   0],\n",
       "       [528,   1,   0],\n",
       "       [616,   1,   0],\n",
       "       [653,   1,   1]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ChurnTest.csv\").to_numpy()\n",
    "#data.head()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data[:,0:-1], axis=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Churn.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>822</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>376</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1  X2  X3  X4         X5  X6  X7  X8         X9  Y\n",
       "0  619   0  42   2       0.00   1   1   1  101348.88  1\n",
       "1  502   0  42   8  159660.80   3   1   0  113931.57  1\n",
       "2  645   1  44   8  113755.78   2   1   0  149756.71  1\n",
       "3  822   1  50   7       0.00   2   1   1   10062.80  0\n",
       "4  376   0  29   4  115046.74   4   1   0  119346.88  1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"Churn.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.FacetGrid(data, hue=\"Y\", height=4).map(plt.scatter, \"X1\", \"X2\").add_legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate metric for split (entropy)\n",
    "#def calc_entropy(obs_list):\n",
    "#    ent = 0\n",
    " #   for unique_class in set(obs_list.iloc[:,-1]):\n",
    "  #      prop = len(obs_list[obs_list.iloc[:,-1]==unique_class]) / len(obs_list)\n",
    "   #     ent += (-1 * prop) * np.log2(prop)\n",
    "    #return ent\n",
    "\n",
    "#calc_entropy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9751150605666907"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to calculate cost function for split (entropy)\n",
    "def calc_entropy(y_vals):\n",
    "    ent = 0\n",
    "    for y_val in set(y_vals):\n",
    "        prop = len([val for val in y_vals if val==y_val]) / len(y_vals)\n",
    "        ent += (-1 * prop) * np.log2(prop) # update entropy using formula\n",
    "    return ent\n",
    "\n",
    "calc_entropy(data[:,-1])\n",
    "#test_list = [1, 0, 1, 1, 1]\n",
    "#calc_entropy(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data\n",
    "def split_data(pred_idx, pred_val, data):\n",
    "    left_node = data[data[:,pred_idx] < pred_val] # left holds obs with vals less than pred_val\n",
    "    right_node = data[data[:,pred_idx] >= pred_val] # right holds obs with vals greater than or equal to pred_val\n",
    "    return left_node, right_node\n",
    "\n",
    "#left, right = split_data(0, 600, data)\n",
    "#print(\"left: \", left)\n",
    "#print(\"right: \", right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004938050068641009"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to calculate information gain\n",
    "def calc_infogain(parent_yvals, left_yvals, right_yvals):\n",
    "    H = calc_entropy(parent_yvals) # entropy of parent node\n",
    "    #print(\"H: \", H)\n",
    "    H_left = calc_entropy(left_yvals) # entropy of left child node\n",
    "    #print(\"H_left: \", H_left)\n",
    "    H_right = calc_entropy(right_yvals) # entropy of right child node\n",
    "    #print(\"H_right: \", H_right)\n",
    "    P_left = len(left_yvals) / len(parent_yvals)\n",
    "    P_right = len(right_yvals) / len(parent_yvals)\n",
    "    cond_entropy = (H_left * P_left) + (H_right * P_right) # conditional entropy to compare to parent node\n",
    "    #print(\"cond_entropy: \", cond_entropy)\n",
    "    return H - cond_entropy # difference between parent node and child node entropy\n",
    "\n",
    "parent_y = data[:,-1]\n",
    "left_node, right_node = split_data(0, 400, data)\n",
    "#print(left_node)\n",
    "#print(right_node)\n",
    "calc_infogain(parent_y, [obs[-1] for obs in left_node], [obs[-1] for obs in right_node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_infogain 0.000640876886273789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred_idx': 8,\n",
       " 'pred_val': 99187.11793800001,\n",
       " 'left': array([[8.220000e+02, 1.000000e+00, 5.000000e+01, ..., 1.000000e+00,\n",
       "         1.006280e+04, 0.000000e+00],\n",
       "        [5.010000e+02, 1.000000e+00, 4.400000e+01, ..., 1.000000e+00,\n",
       "         7.494050e+04, 0.000000e+00],\n",
       "        [6.840000e+02, 1.000000e+00, 2.700000e+01, ..., 1.000000e+00,\n",
       "         7.172573e+04, 0.000000e+00],\n",
       "        ...,\n",
       "        [7.090000e+02, 0.000000e+00, 3.600000e+01, ..., 1.000000e+00,\n",
       "         4.208558e+04, 1.000000e+00],\n",
       "        [7.720000e+02, 1.000000e+00, 4.200000e+01, ..., 0.000000e+00,\n",
       "         9.288852e+04, 1.000000e+00],\n",
       "        [7.920000e+02, 0.000000e+00, 2.800000e+01, ..., 0.000000e+00,\n",
       "         3.819078e+04, 0.000000e+00]]),\n",
       " 'right': array([[6.1900000e+02, 0.0000000e+00, 4.2000000e+01, ..., 1.0000000e+00,\n",
       "         1.0134888e+05, 1.0000000e+00],\n",
       "        [5.0200000e+02, 0.0000000e+00, 4.2000000e+01, ..., 0.0000000e+00,\n",
       "         1.1393157e+05, 1.0000000e+00],\n",
       "        [6.4500000e+02, 1.0000000e+00, 4.4000000e+01, ..., 0.0000000e+00,\n",
       "         1.4975671e+05, 1.0000000e+00],\n",
       "        ...,\n",
       "        [6.5500000e+02, 0.0000000e+00, 4.6000000e+01, ..., 0.0000000e+00,\n",
       "         1.1514640e+05, 1.0000000e+00],\n",
       "        [6.1300000e+02, 1.0000000e+00, 4.0000000e+01, ..., 0.0000000e+00,\n",
       "         1.5132524e+05, 0.0000000e+00],\n",
       "        [5.1600000e+02, 1.0000000e+00, 3.5000000e+01, ..., 1.0000000e+00,\n",
       "         1.0169977e+05, 0.0000000e+00]])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to determine best split (or no split)\n",
    "def best_split(data):\n",
    "    y_vals = data[:,-1] # extract response values from data\n",
    "    max_infogain = 0\n",
    "    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total predictors\n",
    "    pred_idxs_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\n",
    "    pred_vals_to_test = np.mean(data[:,0:-1], axis=0)[pred_idxs_to_test] # use mean value for each predictor as split value\n",
    "    #print(pred_idxs_to_test)\n",
    "    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\n",
    "    for i in range(len(pred_idxs_to_test)): # for each predictor in random subset\n",
    "        left, right = split_data(pred_idxs_to_test[i], pred_vals_to_test[i], data) # split data on mean value for each predictor\n",
    "        infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\n",
    "        if infogain > max_infogain: # determine if split increases information gain / reduces entropy\n",
    "            max_infogain = infogain\n",
    "            best_idx = pred_idxs_to_test[i]\n",
    "            best_val = pred_vals_to_test[i]\n",
    "            best_left, best_right = left, right\n",
    "    print(\"max_infogain\", max_infogain)\n",
    "    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\n",
    "\n",
    "best_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 8]\n",
      "max_infogain 0.01762366920019498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred_idx': 4,\n",
       " 'pred_val': 3768.69,\n",
       " 'left': array([[6.1900000e+02, 0.0000000e+00, 4.2000000e+01, ..., 1.0000000e+00,\n",
       "         1.0134888e+05, 1.0000000e+00],\n",
       "        [8.2200000e+02, 1.0000000e+00, 5.0000000e+01, ..., 1.0000000e+00,\n",
       "         1.0062800e+04, 0.0000000e+00],\n",
       "        [7.2600000e+02, 0.0000000e+00, 2.4000000e+01, ..., 1.0000000e+00,\n",
       "         5.4724030e+04, 0.0000000e+00],\n",
       "        ...,\n",
       "        [6.1300000e+02, 1.0000000e+00, 4.0000000e+01, ..., 0.0000000e+00,\n",
       "         1.5132524e+05, 0.0000000e+00],\n",
       "        [7.7500000e+02, 1.0000000e+00, 3.0000000e+01, ..., 0.0000000e+00,\n",
       "         4.9337840e+04, 0.0000000e+00],\n",
       "        [7.0900000e+02, 0.0000000e+00, 3.6000000e+01, ..., 1.0000000e+00,\n",
       "         4.2085580e+04, 1.0000000e+00]]),\n",
       " 'right': array([[5.0200000e+02, 0.0000000e+00, 4.2000000e+01, ..., 0.0000000e+00,\n",
       "         1.1393157e+05, 1.0000000e+00],\n",
       "        [6.4500000e+02, 1.0000000e+00, 4.4000000e+01, ..., 0.0000000e+00,\n",
       "         1.4975671e+05, 1.0000000e+00],\n",
       "        [3.7600000e+02, 0.0000000e+00, 2.9000000e+01, ..., 0.0000000e+00,\n",
       "         1.1934688e+05, 1.0000000e+00],\n",
       "        ...,\n",
       "        [5.1600000e+02, 1.0000000e+00, 3.5000000e+01, ..., 1.0000000e+00,\n",
       "         1.0169977e+05, 0.0000000e+00],\n",
       "        [7.7200000e+02, 1.0000000e+00, 4.2000000e+01, ..., 0.0000000e+00,\n",
       "         9.2888520e+04, 1.0000000e+00],\n",
       "        [7.9200000e+02, 0.0000000e+00, 2.8000000e+01, ..., 0.0000000e+00,\n",
       "         3.8190780e+04, 0.0000000e+00]])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to determine best split (or no split)\n",
    "def best_split(data):\n",
    "    y_vals = data[:,-1] # extract response values from data\n",
    "    max_infogain = 0\n",
    "    m = int(np.round(np.sqrt(data.shape[1]-1))) # set number of predectors to test = sqrt total predictors\n",
    "    pred_vals_to_test = np.random.choice(range(0,data.shape[1]-1),m, replace=False) # select random subset of predictors to test\n",
    "    print(pred_vals_to_test)\n",
    "    #max_infogain, best_idx, best_val, best_left, best_right = 0, 999, 999, list(), list()\n",
    "    for idx in pred_vals_to_test:\n",
    "        for row in data:\n",
    "            left, right = split_data(idx, row[idx], data)\n",
    "            infogain = calc_infogain(y_vals, [obs[-1] for obs in left], [obs[-1] for obs in right])\n",
    "            #print(\"infogain: \", infogain)\n",
    "            if infogain > max_infogain:\n",
    "                max_infogain = infogain\n",
    "                best_idx = idx\n",
    "                best_val = row[idx]\n",
    "                best_left, best_right = left, right\n",
    "    print(\"max_infogain\", max_infogain)\n",
    "    return {\"pred_idx\": best_idx, \"pred_val\": best_val, \"left\": best_left, \"right\": best_right}\n",
    "\n",
    "best_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build decision tree\n",
    "def build_tree(params):\n",
    "    return \"tree has been built!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "http://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15381-s06/www/DTs.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
